{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34ac9822",
   "metadata": {},
   "source": [
    "# 02_feature_engineering_v2.2_pro_fixed\n",
    "\n",
    "Fixed, GPU-aware feature engineering notebook.\n",
    "\n",
    "Key fixes:\n",
    "- Disables Stumpy/Numba GPU to avoid TSFresh crashes while keeping system GPU available for LightGBM\n",
    "- Safe oscillator building (no duplicate columns)\n",
    "- Auto-detection of oscillator column names for composites\n",
    "- Efficient TSFresh extraction (CPU) + LightGBM training (GPU if available)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3586542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment flags set: STUMPY_USE_GPU=false, NUMBA_DISABLE_CUDA=1\n"
     ]
    }
   ],
   "source": [
    "# 0) Environment safety for TSFresh / Stumpy (RUN this first)\n",
    "import os, warnings\n",
    "# Prevent stumpy/numba from initializing CUDA kernels (avoids Windows/numba crash)\n",
    "os.environ[\"STUMPY_USE_GPU\"] = \"false\"\n",
    "os.environ[\"NUMBA_DISABLE_CUDA\"] = \"1\"\n",
    "warnings.filterwarnings('ignore')\n",
    "print('Environment flags set: STUMPY_USE_GPU=false, NUMBA_DISABLE_CUDA=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62504954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths prepared: E:\\NuFinTech\\notebooks\\data\\interim E:\\NuFinTech\\notebooks\\data\\processed E:\\NuFinTech\\notebooks\\models E:\\NuFinTech\\notebooks\\reports\n"
     ]
    }
   ],
   "source": [
    "# 1) Paths & lightweight imports\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd, math, json\n",
    "ROOT = Path('.').resolve()\n",
    "DATA = ROOT/'data'\n",
    "INTERIM = DATA/'interim'\n",
    "PROCESSED = DATA/'processed'\n",
    "MODELS = ROOT/'models'\n",
    "REPORTS = ROOT/'reports'\n",
    "for p in [INTERIM, PROCESSED, MODELS, REPORTS]: p.mkdir(parents=True, exist_ok=True)\n",
    "print('Paths prepared:', INTERIM, PROCESSED, MODELS, REPORTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "559d24b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded synthetic: E:\\NuFinTech\\notebooks\\data\\processed\\synthetic_trades.parquet\n",
      "rows: 2000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trade_id</th>\n",
       "      <th>symbol</th>\n",
       "      <th>entry_date</th>\n",
       "      <th>exit_date</th>\n",
       "      <th>entry_cost</th>\n",
       "      <th>exit_cost</th>\n",
       "      <th>pnl</th>\n",
       "      <th>net_gex</th>\n",
       "      <th>gamma_flip_strike_perc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>2024-01-01 09:00:00</td>\n",
       "      <td>98.048965</td>\n",
       "      <td>98.697820</td>\n",
       "      <td>0.127840</td>\n",
       "      <td>-5.504625</td>\n",
       "      <td>0.470282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>2024-01-01 09:00:00</td>\n",
       "      <td>100.777792</td>\n",
       "      <td>100.066031</td>\n",
       "      <td>1.127241</td>\n",
       "      <td>-0.054636</td>\n",
       "      <td>0.439699</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>2024-01-01 05:00:00</td>\n",
       "      <td>100.878450</td>\n",
       "      <td>99.950074</td>\n",
       "      <td>-0.184862</td>\n",
       "      <td>-3.242045</td>\n",
       "      <td>-0.479441</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>2024-01-01 04:00:00</td>\n",
       "      <td>99.647866</td>\n",
       "      <td>100.532309</td>\n",
       "      <td>0.365444</td>\n",
       "      <td>6.681929</td>\n",
       "      <td>-0.214164</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>2024-01-02 02:00:00</td>\n",
       "      <td>99.487757</td>\n",
       "      <td>99.186227</td>\n",
       "      <td>0.615979</td>\n",
       "      <td>2.035117</td>\n",
       "      <td>-0.203208</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trade_id symbol entry_date           exit_date  entry_cost   exit_cost  \\\n",
       "0         0   AAPL 2024-01-01 2024-01-01 09:00:00   98.048965   98.697820   \n",
       "1         1   GOOG 2024-01-01 2024-01-01 09:00:00  100.777792  100.066031   \n",
       "2         2   GOOG 2024-01-01 2024-01-01 05:00:00  100.878450   99.950074   \n",
       "3         3   GOOG 2024-01-01 2024-01-01 04:00:00   99.647866  100.532309   \n",
       "4         4   GOOG 2024-01-02 2024-01-02 02:00:00   99.487757   99.186227   \n",
       "\n",
       "        pnl   net_gex  gamma_flip_strike_perc  label  \n",
       "0  0.127840 -5.504625                0.470282      1  \n",
       "1  1.127241 -0.054636                0.439699      1  \n",
       "2 -0.184862 -3.242045               -0.479441      0  \n",
       "3  0.365444  6.681929               -0.214164      1  \n",
       "4  0.615979  2.035117               -0.203208      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Load data (use processed synthetic if present otherwise try combined_files.zip)\n",
    "import zipfile, io\n",
    "synth = PROCESSED / 'synthetic_trades.parquet'\n",
    "if synth.exists():\n",
    "    df = pd.read_parquet(synth)\n",
    "    print('Loaded synthetic:', synth)\n",
    "else:\n",
    "    zpath = Path('data') / 'raw' / 'combined_files.zip'\n",
    "    if zpath.exists():\n",
    "        z = zipfile.ZipFile(zpath)\n",
    "        df = None\n",
    "        for n in z.namelist():\n",
    "            if n.lower().endswith('.parquet'):\n",
    "                df = pd.read_parquet(io.BytesIO(z.read(n))); break\n",
    "            if n.lower().endswith('.csv'):\n",
    "                df = pd.read_csv(io.BytesIO(z.read(n))); break\n",
    "        if df is None:\n",
    "            raise FileNotFoundError('No csv/parquet in zip')\n",
    "        print('Loaded from zip:', zpath)\n",
    "    else:\n",
    "        # generate small synthetic for quick runs\n",
    "        def gen(n=3000):\n",
    "            rng = np.random.default_rng(42)\n",
    "            rows = []\n",
    "            for i in range(n):\n",
    "                net = float(rng.normal(0,1)*(1+rng.random()*3))\n",
    "                flip = float(rng.normal(0,0.6))\n",
    "                pnl = float(rng.normal(0,1))\n",
    "                rows.append({'trade_id': int(i),'entry_date': pd.Timestamp('2024-01-01')+pd.Timedelta(days=i//10),\n",
    "                             'net_gex': net, 'gamma_flip_strike_perc': flip, 'pnl': pnl})\n",
    "            df = pd.DataFrame(rows); df['label'] = (df['pnl']>0).astype(int); return df\n",
    "        df = gen(3000); df.to_parquet(synth, index=False); print('Synthetic generated')\n",
    "\n",
    "print('rows:', len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "827de895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oscillators written (2000, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trade_id</th>\n",
       "      <th>net_gex_mean</th>\n",
       "      <th>net_gex_std</th>\n",
       "      <th>net_gex_z</th>\n",
       "      <th>net_gex_osc</th>\n",
       "      <th>net_gex_mom</th>\n",
       "      <th>net_gex_mom_tanh</th>\n",
       "      <th>gamma_flip_strike_perc_mean</th>\n",
       "      <th>gamma_flip_strike_perc_std</th>\n",
       "      <th>gamma_flip_strike_perc_z</th>\n",
       "      <th>gamma_flip_strike_perc_osc</th>\n",
       "      <th>gamma_flip_strike_perc_mom</th>\n",
       "      <th>gamma_flip_strike_perc_mom_tanh</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trade_id  net_gex_mean  net_gex_std  net_gex_z  net_gex_osc  net_gex_mom  \\\n",
       "0         0           NaN          NaN        NaN          NaN          NaN   \n",
       "1         1           NaN          NaN        NaN          NaN          NaN   \n",
       "2         2           NaN          NaN        NaN          NaN          NaN   \n",
       "3         3           NaN          NaN        NaN          NaN          NaN   \n",
       "4         4           NaN          NaN        NaN          NaN          NaN   \n",
       "\n",
       "   net_gex_mom_tanh  gamma_flip_strike_perc_mean  gamma_flip_strike_perc_std  \\\n",
       "0               NaN                          NaN                         NaN   \n",
       "1               NaN                          NaN                         NaN   \n",
       "2               NaN                          NaN                         NaN   \n",
       "3               NaN                          NaN                         NaN   \n",
       "4               NaN                          NaN                         NaN   \n",
       "\n",
       "   gamma_flip_strike_perc_z  gamma_flip_strike_perc_osc  \\\n",
       "0                       NaN                         NaN   \n",
       "1                       NaN                         NaN   \n",
       "2                       NaN                         NaN   \n",
       "3                       NaN                         NaN   \n",
       "4                       NaN                         NaN   \n",
       "\n",
       "   gamma_flip_strike_perc_mom  gamma_flip_strike_perc_mom_tanh  label  \n",
       "0                         NaN                              NaN      1  \n",
       "1                         NaN                              NaN      1  \n",
       "2                         NaN                              NaN      0  \n",
       "3                         NaN                              NaN      1  \n",
       "4                         NaN                              NaN      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Safe oscillator builder - build per-column and merge by key (no duplicate names)\n",
    "ROLL_Z, MOM_N = 100, 5\n",
    "def build_osc(df, col):\n",
    "    s = df[col].astype(float)\n",
    "    out = pd.DataFrame({'trade_id': df['trade_id']})\n",
    "    out[f'{col}_mean'] = s.rolling(ROLL_Z, min_periods=10).mean()\n",
    "    out[f'{col}_std'] = s.rolling(ROLL_Z, min_periods=10).std().replace(0,1e-6)\n",
    "    out[f'{col}_z'] = (s - out[f'{col}_mean']) / out[f'{col}_std']\n",
    "    out[f'{col}_osc'] = np.tanh(out[f'{col}_z'])\n",
    "    out[f'{col}_mom'] = (s - s.shift(MOM_N)) / (s.shift(MOM_N).abs() + 1e-9)\n",
    "    out[f'{col}_mom_tanh'] = np.tanh(out[f'{col}_mom'])\n",
    "    return out\n",
    "\n",
    "cols = ['net_gex','gamma_flip_strike_perc']\n",
    "frames = []\n",
    "for c in cols:\n",
    "    if c not in df.columns:\n",
    "        print('missing column', c); continue\n",
    "    tmp = build_osc(df, c)\n",
    "    frames.append(tmp)\n",
    "# merge safely on trade_id\n",
    "from functools import reduce\n",
    "osc = reduce(lambda left,right: left.merge(right, on='trade_id', how='outer'), frames).drop_duplicates('trade_id')\n",
    "osc = osc.merge(df[['trade_id','label']], on='trade_id', how='left')\n",
    "osc.to_parquet(PROCESSED/'oscillators_v2_fixed.parquet', index=False)\n",
    "print('Oscillators written', osc.shape)\n",
    "osc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25e88e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged composites saved (2000, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trade_id</th>\n",
       "      <th>net_gex_mean</th>\n",
       "      <th>net_gex_std</th>\n",
       "      <th>net_gex_z</th>\n",
       "      <th>net_gex_osc</th>\n",
       "      <th>net_gex_mom</th>\n",
       "      <th>net_gex_mom_tanh</th>\n",
       "      <th>gamma_flip_strike_perc_mean</th>\n",
       "      <th>gamma_flip_strike_perc_std</th>\n",
       "      <th>gamma_flip_strike_perc_z</th>\n",
       "      <th>...</th>\n",
       "      <th>gamma_flip_strike_perc_mom</th>\n",
       "      <th>gamma_flip_strike_perc_mom_tanh</th>\n",
       "      <th>label</th>\n",
       "      <th>net_gex_stability</th>\n",
       "      <th>net_gex_vol_potential</th>\n",
       "      <th>net_gex_instability</th>\n",
       "      <th>gamma_flip_strike_perc_stability</th>\n",
       "      <th>gamma_flip_strike_perc_vol_potential</th>\n",
       "      <th>gamma_flip_strike_perc_instability</th>\n",
       "      <th>gex_gamma_interact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trade_id  net_gex_mean  net_gex_std  net_gex_z  net_gex_osc  net_gex_mom  \\\n",
       "0         0           0.0          0.0        0.0          0.0          0.0   \n",
       "1         1           0.0          0.0        0.0          0.0          0.0   \n",
       "2         2           0.0          0.0        0.0          0.0          0.0   \n",
       "3         3           0.0          0.0        0.0          0.0          0.0   \n",
       "4         4           0.0          0.0        0.0          0.0          0.0   \n",
       "\n",
       "   net_gex_mom_tanh  gamma_flip_strike_perc_mean  gamma_flip_strike_perc_std  \\\n",
       "0               0.0                          0.0                         0.0   \n",
       "1               0.0                          0.0                         0.0   \n",
       "2               0.0                          0.0                         0.0   \n",
       "3               0.0                          0.0                         0.0   \n",
       "4               0.0                          0.0                         0.0   \n",
       "\n",
       "   gamma_flip_strike_perc_z  ...  gamma_flip_strike_perc_mom  \\\n",
       "0                       0.0  ...                         0.0   \n",
       "1                       0.0  ...                         0.0   \n",
       "2                       0.0  ...                         0.0   \n",
       "3                       0.0  ...                         0.0   \n",
       "4                       0.0  ...                         0.0   \n",
       "\n",
       "   gamma_flip_strike_perc_mom_tanh  label  net_gex_stability  \\\n",
       "0                              0.0      1                0.0   \n",
       "1                              0.0      1                0.0   \n",
       "2                              0.0      0                0.0   \n",
       "3                              0.0      1                0.0   \n",
       "4                              0.0      1                0.0   \n",
       "\n",
       "   net_gex_vol_potential  net_gex_instability  \\\n",
       "0                    0.0                  0.0   \n",
       "1                    0.0                  0.0   \n",
       "2                    0.0                  0.0   \n",
       "3                    0.0                  0.0   \n",
       "4                    0.0                  0.0   \n",
       "\n",
       "   gamma_flip_strike_perc_stability  gamma_flip_strike_perc_vol_potential  \\\n",
       "0                               0.0                                   0.0   \n",
       "1                               0.0                                   0.0   \n",
       "2                               0.0                                   0.0   \n",
       "3                               0.0                                   0.0   \n",
       "4                               0.0                                   0.0   \n",
       "\n",
       "   gamma_flip_strike_perc_instability  gex_gamma_interact  \n",
       "0                                 0.0                 0.0  \n",
       "1                                 0.0                 0.0  \n",
       "2                                 0.0                 0.0  \n",
       "3                                 0.0                 0.0  \n",
       "4                                 0.0                 0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) Semantically rich composites - auto-detect oscillator columns (no hard-coded names)\n",
    "merged = pd.read_parquet(PROCESSED/'oscillators_v2_fixed.parquet')\n",
    "\n",
    "def find_col_for(prefix, key):\n",
    "    # find first column that contains prefix AND key\n",
    "    for col in merged.columns:\n",
    "        if prefix in col and key in col:\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "for c in cols:\n",
    "    osc_col = find_col_for(c, '_osc')\n",
    "    z_col = find_col_for(c, '_z')\n",
    "    mom_col = find_col_for(c, '_mom_tanh')\n",
    "    if not osc_col or not z_col or not mom_col:\n",
    "        print(f'Skipping composites for {c} - missing columns', osc_col, z_col, mom_col)\n",
    "        continue\n",
    "    merged[f'{c}_stability'] = 1 - merged[osc_col].abs()\n",
    "    merged[f'{c}_vol_potential'] = (1 - merged[z_col].abs()) * merged[mom_col].abs()\n",
    "    merged[f'{c}_instability'] = merged[mom_col].abs() * (1 - merged[z_col].abs())\n",
    "\n",
    "# Interaction term if both exist\n",
    "try:\n",
    "    gex_vol = [cc for cc in merged.columns if 'net_gex' in cc and 'vol_potential' in cc][0]\n",
    "    gamma_vol = [cc for cc in merged.columns if 'gamma_flip' in cc and 'vol_potential' in cc][0]\n",
    "    merged['gex_gamma_interact'] = merged[gex_vol] * merged[gamma_vol]\n",
    "except Exception:\n",
    "    print('Could not build interaction term (columns missing)')\n",
    "\n",
    "merged = merged.replace([np.inf, -np.inf], np.nan).fillna(0).clip(-1e6, 1e6)\n",
    "merged.to_parquet(PROCESSED/'merged_composites_v2_fixed.parquet', index=False)\n",
    "print('Merged composites saved', merged.shape)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a87eb065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long form shape: (40000, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|███████████████████████████████████████████████████████████| 20/20 [11:39<00:00, 34.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSFresh features saved (2000, 14763)\n"
     ]
    }
   ],
   "source": [
    "# 5) TSFresh extraction (CPU-safe) - build small long-form per trade\n",
    "import numpy as _np\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.feature_extraction import EfficientFCParameters\n",
    "\n",
    "merged = pd.read_parquet(PROCESSED/'merged_composites_v2_fixed.parquet')\n",
    "ids = merged['trade_id'].unique()\n",
    "MAX_IDS = min(2000, len(ids))\n",
    "ids = ids[:MAX_IDS]\n",
    "WINDOW = 20\n",
    "rows = []\n",
    "for tid in ids:\n",
    "    row = merged[merged.trade_id == tid].iloc[0]\n",
    "    for t in range(WINDOW):\n",
    "        rec = {'id': int(tid), 'time': int(t)}\n",
    "        for c in merged.columns:\n",
    "            if c in ['trade_id','label']: continue\n",
    "            rec[c] = float(row[c]) * (1.0 + 0.01 * _np.random.randn())\n",
    "        rows.append(rec)\n",
    "ts = pd.DataFrame(rows)\n",
    "print('Long form shape:', ts.shape)\n",
    "\n",
    "fc = EfficientFCParameters()\n",
    "feat = extract_features(ts, column_id='id', column_sort='time', default_fc_parameters=fc, n_jobs=4)\n",
    "feat = feat.fillna(0)\n",
    "feat.to_parquet(PROCESSED/'tsfresh_eff_features_fixed.parquet')\n",
    "print('TSFresh features saved', feat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38fccf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_full_v2_fixed saved (2000, 14782)\n",
      "Saved selected features (2000, 60)\n"
     ]
    }
   ],
   "source": [
    "# 6) Merge features + selection\n",
    "feat = pd.read_parquet(PROCESSED/'tsfresh_eff_features_fixed.parquet')\n",
    "comp = pd.read_parquet(PROCESSED/'merged_composites_v2_fixed.parquet').set_index('trade_id')\n",
    "comp = comp.loc[comp.index.intersection(feat.index)]\n",
    "X_full = pd.concat([comp.drop(columns=['label'], errors='ignore'), feat.reindex(comp.index)], axis=1).fillna(0)\n",
    "y = comp['label']\n",
    "X_full = X_full.replace([np.inf, -np.inf], np.nan).fillna(0).clip(-1e6, 1e6)\n",
    "X_full.to_parquet(PROCESSED/'features_full_v2_fixed.parquet')\n",
    "print('features_full_v2_fixed saved', X_full.shape)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=300, n_jobs=4, random_state=42)\n",
    "rf.fit(X_full, y)\n",
    "imp = pd.Series(rf.feature_importances_, index=X_full.columns).sort_values(ascending=False)\n",
    "TOP = 60\n",
    "sel = imp.head(TOP).index.tolist()\n",
    "pd.Series(sel).to_csv(MODELS/'selected_features_v2_fixed.csv', index=False)\n",
    "X_sel = X_full[sel]\n",
    "X_sel.to_parquet(PROCESSED/'features_train_v2_fixed.parquet')\n",
    "print('Saved selected features', X_sel.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9de5ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 788, number of negative: 812\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 15300\n",
      "[LightGBM] [Info] Number of data points in the train set: 1600, number of used features: 60\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 60 dense feature groups (0.09 MB) transferred to GPU in 0.001810 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492500 -> initscore=-0.030002\n",
      "[LightGBM] [Info] Start training from score -0.030002\n",
      "✅ LightGBM AUC: 0.5633 | GPU used: True\n",
      "✅ RF AUC: 0.5746\n",
      "✅ Stacked AUC: 0.5798\n"
     ]
    }
   ],
   "source": [
    "# --- Fixed LightGBM Training (handles GPU + special character feature names) ---\n",
    "import re, joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Load features\n",
    "X = pd.read_parquet(PROCESSED / 'features_train_v2_fixed.parquet')\n",
    "y = y.reindex(X.index).fillna(0).astype(int)\n",
    "\n",
    "# --- Sanitize feature names for LightGBM ---\n",
    "def sanitize_columns(df):\n",
    "    safe_cols = []\n",
    "    for c in df.columns:\n",
    "        new_c = re.sub(r'[^A-Za-z0-9_]+', '_', c)  # replace all special chars\n",
    "        safe_cols.append(new_c)\n",
    "    df.columns = safe_cols\n",
    "    return df\n",
    "\n",
    "X = sanitize_columns(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "use_gpu = False\n",
    "auc_lgb = None\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    params = {\n",
    "        'n_estimators': 1000,\n",
    "        'learning_rate': 0.05,\n",
    "        'num_leaves': 31,\n",
    "        'n_jobs': -1,\n",
    "        'device': 'gpu'  # try GPU first\n",
    "    }\n",
    "\n",
    "    lgb_clf = lgb.LGBMClassifier(**params)\n",
    "    callbacks = [lgb.early_stopping(50, verbose=False)]\n",
    "\n",
    "    try:\n",
    "        lgb_clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=callbacks)\n",
    "        use_gpu = True\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ GPU training failed:\", e)\n",
    "        params['device'] = 'cpu'\n",
    "        lgb_clf = lgb.LGBMClassifier(**params)\n",
    "        lgb_clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=callbacks)\n",
    "\n",
    "    p_val = lgb_clf.predict_proba(X_val)[:, 1]\n",
    "    auc_lgb = roc_auc_score(y_val, p_val)\n",
    "    print(f\"✅ LightGBM AUC: {auc_lgb:.4f} | GPU used: {use_gpu}\")\n",
    "    joblib.dump(lgb_clf, MODELS / 'lgb_model_v2_final.pkl')\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ LightGBM training failed:\", e)\n",
    "\n",
    "# --- RandomForest baseline ---\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=400, n_jobs=4, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "p_rf = rf.predict_proba(X_val)[:, 1]\n",
    "auc_rf = roc_auc_score(y_val, p_rf)\n",
    "print(f\"✅ RF AUC: {auc_rf:.4f}\")\n",
    "\n",
    "# --- Ensemble stack if LightGBM succeeded ---\n",
    "if auc_lgb:\n",
    "    import numpy as np\n",
    "    stack = np.mean([p_val, p_rf], axis=0)\n",
    "    auc_stack = roc_auc_score(y_val, stack)\n",
    "    print(f\"✅ Stacked AUC: {auc_stack:.4f}\")\n",
    "else:\n",
    "    auc_stack = auc_rf\n",
    "\n",
    "# Save results\n",
    "pd.Series({\n",
    "    'auc_lgb': auc_lgb,\n",
    "    'auc_rf': auc_rf,\n",
    "    'auc_stack': auc_stack\n",
    "}).to_csv(REPORTS / 'metrics_v2_final.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8405fa-30b0-43c8-834d-2e732f9567da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
