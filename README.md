# ğŸš€ FEATURE ENGINEERING, MODELING & PATTERN DISCOVERY PIPELINE

---

## ğŸ§© MODULE 1: FEATURE ENGINEERING & SELECTION

### <img src="https://github.com/user-attachments/assets/6672ee8c-15ed-4fb5-9cd5-63c04ac747c1" height="20px" style="vertical-align:bottom;"> Working:
Three-stage feature reduction process applied to prevent data leakage and optimize model performance:  
1ï¸âƒ£ Analyzed **190 raw features** for redundancy via correlation analysis, low-variance detection, and one-hot group identification,  
2ï¸âƒ£ Performed **80/20 stratified train-test split BEFORE any feature engineering** to ensure zero information leakage, created target-encoded features using only training data statistics,  
3ï¸âƒ£ Reduced features from **81 to 50** through time-window consolidation (kept 5d, dropped other variants), domain-based filtering with Random Forest importance verification, and final importance-based ranking,  
4ï¸âƒ£ Validated that feature reduction maintained test performance while reducing overfitting.

### ğŸ“¦ Output Files:

###  <img src="https://github.com/user-attachments/assets/f3dcee8e-e008-457a-97fb-d3848b425713" height="20px" style="vertical-align:text-bottom;"> Module 1.1 (Feature Cleanup Analysis):
- `features_to_drop.txt` ğŸ—‘ï¸ â€“ List of redundant features identified for removal  
- `cleaned_features.txt` ğŸ§¹ â€“ Initial cleaned feature list after redundancy removal  
- `feature_analysis_report.json` ğŸ“Š â€“ Detailed redundancy analysis with correlation and variance statistics  

###  <img src="https://github.com/user-attachments/assets/f3dcee8e-e008-457a-97fb-d3848b425713" height="20px" style="vertical-align:text-bottom;"> Module 1.1b (Dataset Preparation):
- `train_prepared.parquet` ğŸ‹ï¸ â€“ Training dataset with **13,600 samples** and engineered features  
- `test_prepared.parquet` ğŸ§ª â€“ Test dataset with **3,400 samples** using same transformations  
- `prepared_features.txt` ğŸ§¾ â€“ List of **81 features** after cleanup and encoding  
- `feature_engineering_artifacts.json` ğŸ§  â€“ Target encoding maps learned from training data only  
- `dataset_summary.json` ğŸ“ˆ â€“ Train/test split statistics and class distributions  

###  <img src="https://github.com/user-attachments/assets/f3dcee8e-e008-457a-97fb-d3848b425713" height="20px" style="vertical-align:text-bottom;"> Module 1.2 (Feature Reduction):
- `final_features.txt` â­ â€“ Final **50 optimized features** selected for modeling  
- `reduction_summary.json` ğŸ”½ â€“ Step-by-step reduction statistics showing **81 â†’ 50** feature reduction  

###  <img src="https://github.com/user-attachments/assets/f3dcee8e-e008-457a-97fb-d3848b425713" height="20px" style="vertical-align:text-bottom;"> Module 1.3 (Feature Validation):
- `validation_comparison.png` ğŸ“‰ â€“ Train vs test accuracy comparison chart demonstrating overfitting reduction  
- `performance_comparison.csv` ğŸ“‘ â€“ Detailed metrics including train accuracy, test accuracy, and overfitting gap comparison  

---

## ğŸŒ³ MODULE 2: MODEL TRAINING (DECISION TREE CLUSTERING)

### <img src="https://github.com/user-attachments/assets/6672ee8c-15ed-4fb5-9cd5-63c04ac747c1" height="20px" style="vertical-align:bottom;"> Working:
Trained decision tree classifier on **50 optimized features** using training data only with hyperparameters:  
`max_depth=10`, `min_samples_split=30`, `min_samples_leaf=20`,  
resulting in **195 leaf nodes** where each leaf represents a distinct pattern cluster defined by specific feature threshold conditions from root to leaf.

### ğŸ“¦ Output Files:
- `decision_tree_model.pkl` ğŸŒ² â€“ Trained decision tree model with **195 leaf nodes**  
- `model_metadata.json` ğŸ§¾ â€“ Model hyperparameters, tree depth, number of leaves, and feature names  
- `cluster_rules.json` ğŸ“œ â€“ Complete path conditions from root to each leaf for all **195 clusters**  
- `decision_tree.png` ğŸ–¼ï¸ â€“ Tree visualization showing top 3 levels of split logic  
- `confusion_matrix.png` ğŸ¯ â€“ Test set performance visualization  
- `feature_importance.png` ğŸ“Š â€“ Bar chart of top 15 most important features for splitting decisions  

---

## ğŸ§ª MODULE 3: CLUSTER ANALYSIS & QUALITY FILTERING

### <img src="https://github.com/user-attachments/assets/6672ee8c-15ed-4fb5-9cd5-63c04ac747c1" height="20px" style="vertical-align:bottom;"> Working:
Analyzed all **195 decision tree leaf node clusters** on combined train and test data, calculated cluster purity (dominant class percentage), size, and top 5 distinguishing features per cluster, then applied actionable criteria filtering for **purity â‰¥70%** and **size â‰¥50 samples** to identify high-quality patterns, resulting in **42 actionable clusters** meeting quality thresholds.

### ğŸ“¦ Output Files:
- `cluster_statistics.json` ğŸ“˜ â€“ Complete statistics for all **195 clusters** including size, purity, target distribution, and top 5 distinguishing features with percentage differences from global means  
- `actionable_clusters.json` âœ… â€“ **42 patterns** meeting quality criteria with cluster ID, size, purity, dominant class, and confidence score  
- `cluster_distribution.png` ğŸ“Š â€“ Four-panel visualization showing cluster sizes, target distribution by cluster, purity histogram, and size distribution  

---

## ğŸ“ MODULE 4: RULE EXTRACTION & ANALYSIS

### <img src="https://github.com/user-attachments/assets/6672ee8c-15ed-4fb5-9cd5-63c04ac747c1" height="20px" style="vertical-align:bottom;">  Working:
Extracted interpretable decision rules by tracing root-to-leaf paths for **42 actionable clusters**, converting tree split conditions into readable if-then rules, organized rules into **3 confidence tiers** based on purity  
(Tier 1: â‰¥95%, Tier 2: 85â€“95%, Tier 3: 70â€“85%),  
calculated signal strength scores (0â€“10) based on confidence and sample size, then analyzed patterns across rules to identify most important features, common feature combinations, signal direction balance, and potential rule conflicts.

### ğŸ“¦ Output Files:

###  <img src="https://github.com/user-attachments/assets/f3dcee8e-e008-457a-97fb-d3848b425713" height="20px" style="vertical-align:text-bottom;"> Module 4.1 (Rule Extraction):
- `rule_catalog.json` ğŸ“š â€“ All **42 extracted rules** with full conditions, tier assignments, confidence scores, signal strength, and predicted classes  
- `rules_summary.csv` ğŸ§® â€“ Tabular summary with cluster ID, signal direction, confidence percentage, sample size, strength score, and condition count  
- `rules_detailed.txt` ğŸ“ â€“ Human-readable format with complete conditions and trading interpretations for all **42 rules**  
- `rules_quick_reference.txt` âš¡ â€“ Condensed trading desk guide showing only **Tier 1 rules (â‰¥95% confidence)**  

###  <img src="https://github.com/user-attachments/assets/f3dcee8e-e008-457a-97fb-d3848b425713" height="20px" style="vertical-align:text-bottom;"> Module 4.2 (Rule Analysis & Pattern Detection):
- `feature_importance_analysis.png` ğŸ“Š â€“ Dual-panel chart showing overall feature frequency and tier-based breakdown  
- `rule_analysis.json` ğŸ§  â€“ Comprehensive analysis data including feature frequencies by tier, signal direction statistics, top features by direction, and identified conflicts  
- `key_insights.txt` ğŸ’¡ â€“ Actionable summary with top 5 critical features, signal bias assessment, and improvement recommendations  

---

## ğŸ”„ MODULE 5: PATTERN VALIDATION (BACKTESTING & WALK-FORWARD)

### <img src="https://github.com/user-attachments/assets/6672ee8c-15ed-4fb5-9cd5-63c04ac747c1" height="20px" style="vertical-align:bottom;">  Working:
Applied rigorous multi-period validation to **42 actionable patterns** through three stages:  
(1) ğŸ“‰ Backtest validation on **20% held-out test set** measuring out-of-sample accuracy per cluster,  
(2) â­ï¸ Walk-forward validation testing each pattern across **5 independent time periods** to assess temporal stability via mean accuracy, standard deviation, and coefficient of variation,  
(3) ğŸ§ª Comprehensive quality analysis calculating reliability scores (0â€“100) based on sample size adequacy, stability, accuracy consistency, and train-test degradation, then filtering for patterns with **reliability â‰¥70** and no critical issues, resulting in **16 production-quality patterns**.

### ğŸ“¦ Output Files:

###  <img src="https://github.com/user-attachments/assets/f3dcee8e-e008-457a-97fb-d3848b425713" height="20px" style="vertical-align:text-bottom;"> Module 5.1 (Backtesting):
- `cluster_performance.csv` ğŸ“‘ â€“ Per-cluster test set accuracy, sample counts, true positives, false positives, true negatives, false negatives  
- `backtest_summary.json` ğŸ“ˆ â€“ Overall performance statistics across all **42 patterns**  

###  <img src="https://github.com/user-attachments/assets/f3dcee8e-e008-457a-97fb-d3848b425713" height="20px" style="vertical-align:text-bottom;"> Module 5.2 (Walk-Forward Validation):
- `walkforward_stability.csv` ğŸ” â€“ Stability metrics per pattern: mean accuracy across 5 periods, standard deviation, coefficient of variation, minimum and maximum accuracy  
- `walkforward_results_detailed.csv` ğŸ—‚ï¸ â€“ Individual period performance showing accuracy in each of the **5 time windows** per pattern  
- `walkforward_degrading.csv` âš ï¸ â€“ Patterns showing significant performance degradation over time periods  
- `stability_analysis.png` ğŸ“‰ â€“ Visualization of pattern consistency across validation periods  

###  <img src="https://github.com/user-attachments/assets/f3dcee8e-e008-457a-97fb-d3848b425713" height="20px" style="vertical-align:text-bottom;">  Module 5.3 (Quality Analysis & Final Filtering):
- `pattern_quality_analysis.csv` ğŸ… â€“ All **42 patterns** with quality grades (A+ to F), reliability scores, tier assignments, accuracy metrics, stability CV, test sample counts, degradation percentages, and flagged issues  
- `usable_patterns_only.csv` âœ… â€“ **16 patterns** passing final criteria (reliability â‰¥70, issues=CLEAN) ready for consideration  
- `grade_a_patterns.csv` ğŸŒŸ â€“ **14 highest-quality patterns** graded A+ or A representing **87.5% of validated set**

---
